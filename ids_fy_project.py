# -*- coding: utf-8 -*-
"""IDS_FY_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r0A-CYF5U3GbOFwt2brb4rae5Sv5ANeZ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import glob
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

from google.colab import drive

# Mount Google Drive (follow the prompt to authorize)
drive.mount('/content/drive')

path = '/content/drive/MyDrive/CIC-IDS-2017/*.csv'
# Use glob to list all CSV files in the directory
csv_files = glob.glob(path)
# Read and combine all CSV files into one DataFrame
dataframes = [pd.read_csv(file) for file in csv_files]
data = pd.concat(dataframes, ignore_index=True)
print("Dataset shape:", data.shape)
data.head()

# Check for missing values
print("Missing values per column:")
print(data.isnull().sum())

# Example: Drop rows with missing values (or choose an imputation method)
data.dropna(inplace=True)

# Optionally, drop columns that are not needed (e.g., if there are index columns or non-relevant features)
# Replace 'ColumnToDrop' with actual column names you want to remove
# data.drop(['ColumnToDrop1', 'ColumnToDrop2'], axis=1, inplace=True)

# Convert categorical columns to numeric if necessary
# Example: If 'Protocol' is a categorical feature
if 'Protocol' in data.columns:
    data['Protocol'] = data['Protocol'].astype('category').cat.codes

# Verify changes
print(data.head())

data.columns = data.columns.str.strip()  # Removes extra whitespace
data.columns = data.columns.str.lower()    # Optionally, convert to lowercase for consistency
print("Cleaned Columns:")
print(data.columns.tolist())

X = data.drop(['label'], axis=1)
y = data['label']

# If the labels are textual (e.g., "Benign", "Attack"), encode them into numbers
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

print("Features shape:", X.shape)
print("Target distribution:", np.unique(y, return_counts=True))

from sklearn.model_selection import train_test_split

# Split data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Training set shape:", X_train.shape)
print("Testing set shape:", X_test.shape)

import numpy as np

# Check for infinite values in X_train
if not np.all(np.isfinite(X_train)):
    print("X_train contains infinite values.")

# Print basic statistics to see if any values are extremely large
print("X_train statistics:")
print(X_train.describe())

# Replace infinite values with NaN
X_train = X_train.replace([np.inf, -np.inf], np.nan)
X_test = X_test.replace([np.inf, -np.inf], np.nan)

# Option 1: Fill NaN values with the column mean
X_train.fillna(X_train.mean(), inplace=True)
X_test.fillna(X_test.mean(), inplace=True)

# Option 2: Alternatively, drop rows with NaN values
# X_train.dropna(inplace=True)
# X_test.dropna(inplace=True)

X_train = X_train.astype(np.float64)
X_test = X_test.astype(np.float64)

from sklearn.tree import DecisionTreeClassifier

# Initialize the Decision Tree model (you can adjust hyperparameters as needed)
dt_classifier = DecisionTreeClassifier(max_depth=5, random_state=42)

# Train the model on the training data
dt_classifier.fit(X_train, y_train)
print("Decision Tree model trained successfully!")

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Use scaled test set if available; otherwise, use the original test set.
if 'X_test_scaled' in globals():
    X_eval = X_test_scaled
else:
    print("X_test_scaled is not defined; using original X_test for evaluation.")
    X_eval = X_test

# Make predictions on the chosen evaluation set
y_pred = dt_classifier.predict(X_eval)

# Calculate and print the accuracy in percentage format
acc = accuracy_score(y_test, y_pred)
print("Test Set Accuracy: {:.2f}%".format(acc * 100))

# Print the confusion matrix and classification report for additional insights
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_pred))